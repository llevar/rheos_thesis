\begin{Huge}
Zusammenfassung
\end{Huge}\\[1cm]
\noindent
Forscher verwenden zunehmend Cloud-Computing, um umfangreiche Genomik-Analysen effizient und kostengünstig durchzuführen. Erfolgreiche Anwendungen  in der Cloud erfordern sorgfältige Instrumentierung und ein Management, das häufige Probleme wie Ressourcenengpässe und geringe Auslastung vermeidet, die sowohl die Kosten erhöhen als auch den Zeitplan eines wissenschaftlichen Projekts verlängern können.

Um diesen Herausforderungen zu begegnen, haben wir das Framework Butler für ein umfangreiches Management von wissenschaftlichen Workflows in der Cloud entwickelt. Die Eckpfeiler des Butler-Designs sind folgende: Unterstützung mehrerer Clouds, Infrastruktur-Konfigurationsmanagement, skalierbarer, fehlertoleranter Betrieb, umfassende Ressourcenüberwachung sowie automatisierte Fehlererkennung und -wiederherstellung. Butler setzt auf robuste Open-Source-Komponenten, um ein Framework bereitzustellen, das über Tausende von Rechnerkernen und Millionen von Workflow-Ausführungen skalierbar ist. Die Fehlererkennungs- und Selbstheilungsfunktionen von Butler sind einzigartig unter den Frameworks für wissenschaftliche Arbeitsabläufe und gewährleisten, dass die Analysen mit minimalem Eingriff des Menschen durchgeführt werden.

Butler wurde für die Analyse von über 725 TB DNA-Sequenzierdaten in der Cloud verwendet, unter Nutzung von 1500 CPU-Kernen und 6 TB RAM. Damit wurden im Vergleich zu anderen Tools Ergebnisse mit einer um 43\% gesteigerten Effizienz erzielt. Das flexible Design des Butler Frameworks ermöglicht eine einfache Übernahme in andere Bereiche der Biowissenschaften und stellt sicher, dass es hinsichtlich nachgefragter wissenschaftlicher Analysen in der Cloud während der nächsten Jahre skaliert werden kann.

Da viele Bioinformatik-Werkzeuge mit kleinen Stichprobengrößen entwickelt wurden, ist es oft schwierig, mit Anforderungen an die Datenverarbeitung im dem Maßstab Schritt zu halten, der für moderne Forschungs- und klinische Sequenzierungsprojekte erforderlich ist. Das Rheos Softwaresystem wurde speziell für derart große Datenmengen entwickelt. Rheos nutzt die elastischen Rechenkapazitäten moderner akademischer und kommerzieller Clouds und setzt einen serviceorientierten, containerisierten Ansatz für die Implementierung moderner Bioinformatik-Algorithmen ein. Dies ermöglicht es der Software, Skalierbarkeit und Benutzerfreundlichkeit zu erreichen, um so bei hoher Betriebslast erfolgreich große Datensätze, die von Projekten wie dem Internationalem Krebsgenomkonsortium (ICGC) Argo und der Initiative All of Us generiert wurden, zu prozessieren.

Rheos basiert auf einem innovativen, Stream-basierten Ansatz für die Verarbeitung genomischer Daten. Mit Hilfe von Rheos können schnellere Entscheidungen über das Vorhandensein genomischer Mutationen getroffen werden, die Krankheiten wie Krebs auslösen, und so die Wirksamkeit für klinische Sequenzierungsanwendungen verbessert werden. Unsere Tests der innerhalb von Rheos entwickelten Tools zum Auffinden neuartiger Keimbahn-Einzelnukleotid-Polymorphismen (SNP) und Deletionen deuten an, dass Rheos eine Genauigkeit von ~ 98\% beim SNP-Aufruf und ~ 85\% Genauigkeit beim Aufruf von Deletionen erreicht. Dies ist vergleichbar mit anderen führenden Tools wie dem Genome Analysis Toolkit (GATK), Freebayes und Delly.

Die beiden von uns entwickelten Frameworks liefern wichtige Beiträge zur Bewältigung des ständig wachsenden Bedarfs der Analyse großvolumiger genomischer Datensätzen in der Cloud, indem im Fall von Butler die vorhandenen Tools effektiver eingesetzt werden und im Fall von Rheos ein neuer, dynamischer und realer Ansatz zur Echtzeit-Genomanalyse geschaffen wird.
 
\newpage
\null
\thispagestyle{empty}
\newpage